{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scraping de literales con Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import os\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate options\n",
    "opts = Options()\n",
    "\n",
    "# opts.add_argument(\" â€” headless\") # Uncomment if the headless version needed\n",
    "opts.binary_location = r\"C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe\"\n",
    "\n",
    "# Set the location of the webdriver\n",
    "chrome_driver = os.getcwd() + \"\\chromedriver.exe\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getting_webs(sitemap):\n",
    "    # Instantiate a webdriver\n",
    "    driver = webdriver.Chrome(options=opts, executable_path=chrome_driver)\n",
    "    # Load the HTML page\n",
    "    driver.maximize_window()\n",
    "    driver.get(sitemap)\n",
    "    #driver.implicitly_wait(220)\n",
    "    #time.sleep(10)\n",
    "    #javaScript = \"window.scrollTo(0,document.body.scrollHeight);\"\n",
    "    #driver.execute_script(javaScript)\n",
    "    #time.sleep(5)\n",
    "    soup = BeautifulSoup(driver.page_source)\n",
    "    driver.close()\n",
    "    return list(map(lambda x: 'https://shop.mango.com' + x['href'], soup.find_all(lambda tag: tag.name == 'a' and \n",
    "                                   tag.get('class') == ['site-map-item'])))\n",
    "\n",
    "web_list = getting_webs('https://shop.mango.com/es/sitemap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mujer']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'(\\w+)/[\\w-]+$',web_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_web(web):\n",
    "    driver = webdriver.Chrome(options=opts, executable_path=chrome_driver)\n",
    "    driver.maximize_window()\n",
    "    driver.get(web)\n",
    "    driver.implicitly_wait(220)\n",
    "    time.sleep(2)\n",
    "    #Scroll infinito\n",
    "    scroll_pause_time = 0.7 # You can set your own pause time. My laptop is a bit slow so I use 1 sec\n",
    "    screen_height = driver.execute_script(\"return window.screen.height;\")   # get the screen height of the web\n",
    "    i = 5\n",
    "\n",
    "    while True:\n",
    "        # scroll one screen height each time\n",
    "        driver.execute_script(\"window.scrollTo(0, {screen_height}*{i});\".format(screen_height=screen_height, i=i))  \n",
    "        i += 5\n",
    "        time.sleep(scroll_pause_time)\n",
    "        # update scroll height each time after scrolled, as the scroll height can change after we scrolled the page\n",
    "        scroll_height = driver.execute_script(\"return document.body.scrollHeight;\")  \n",
    "        # Break the loop when the height we need to scroll to is larger than the total scroll height\n",
    "        if (screen_height) * i > scroll_height:\n",
    "            break\n",
    "    \n",
    "    soup = BeautifulSoup(driver.page_source)\n",
    "    driver.close()\n",
    "    sex = re.findall(r'(\\w+)/[\\w-]+$',web)[0]\n",
    "    category = soup.find(\"h1\", {\"class\":\"sg-text-subtitle _1ZGtO\"}).getText()\n",
    "    names = soup.find_all(\"span\", {\"class\":\"product-name sg-text-body-small _2uGDp\"})\n",
    "    return (sex, category,list(map(lambda x: x.text, names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(columns=['Sex','Category','Literal'])\n",
    "for web in web_list:\n",
    "    sex, cat,items = scrape_web(web)\n",
    "    web_data = pd.DataFrame({'Sex':sex, 'Category':cat,'Literal':items})\n",
    "    data = data.append(web_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows',None)\n",
    "data.to_excel('literales_mango.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
